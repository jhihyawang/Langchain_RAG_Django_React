from rest_framework import generics, status, filters, pagination
from rest_framework.parsers import MultiPartParser, FormParser
from rest_framework.response import Response
from ..serializers import KnowledgeSerializer,EnterpriseQuerySerializer,EnterpriseQueryResponseSerializer
import os
from django.conf import settings
from django.core.files.storage import default_storage
from rest_framework.views import APIView
from langchain_core.prompts import PromptTemplate
from ..azure_llama_api import AzureLlamaAPI
from .vectorstores import (
    enterprise_vectorstore,
)

class EnterpriseQueryView(generics.CreateAPIView):
    serializer_class = EnterpriseQuerySerializer

    def create(self, request, *args, **kwargs):
        query = request.data.get("query")
        model_type = request.data.get("model_type", "cloud")
        use_retrieval = request.data.get("use_retrieval", True)

        if not query:
            return Response({"error": "Query is required"}, status=status.HTTP_400_BAD_REQUEST)

        print(f"ğŸ” [æŸ¥è©¢è«‹æ±‚] æ”¶åˆ°æŸ¥è©¢: {query}, ä½¿ç”¨æ¨¡å‹: {model_type}, å•Ÿç”¨æª¢ç´¢: {use_retrieval}")

        context = ""
        retrieved_docs = []

        if use_retrieval:
            retriever = enterprise_vectorstore.as_retriever(search_kwargs={"k": 5})
            documents = retriever.get_relevant_documents(query)

            if not documents:
                return Response({
                    "query": query,
                    "answer": "âš ï¸ æœªæ‰¾åˆ°ç›¸é—œå…§å®¹ï¼Œè«‹é‡æ–°è¼¸å…¥å•é¡Œæˆ–æä¾›æ›´å¤šç´°ç¯€ã€‚",
                    "retrieved_docs": []
                }, status=status.HTTP_200_OK)

            print(f"âœ… [æª¢ç´¢çµæœ] æ‰¾åˆ° {len(documents)} ä»½æ–‡ä»¶")

            for doc in documents:
                page_number = doc.metadata.get("page_number", "æœªçŸ¥é ç¢¼")
                title = doc.metadata.get("title", "æœªçŸ¥æ–‡ä»¶")
                retrieved_docs.append({
                    "title": title,
                    "page_number": page_number,
                    "content": doc.page_content
                })

            context = "\n\n".join([doc["content"] for doc in retrieved_docs])

        if use_retrieval:
            prompt = PromptTemplate(
                template="æ ¹æ“šä»¥ä¸‹èƒŒæ™¯è³‡è¨Šå›ç­”å•é¡Œï¼š\n\n{context}\n\nå•é¡Œï¼š{query}\nå›ç­”ï¼š",
                input_variables=["context", "query"]
            )
            formatted_prompt = prompt.format(context=context, query=query)
        else:
            prompt = PromptTemplate(
                template="è«‹å›ç­”ä»¥ä¸‹å•é¡Œï¼š\n\nå•é¡Œï¼š{query}\nå›ç­”ï¼š",
                input_variables=["query"]
            )
            formatted_prompt = prompt.format(query=query)

        print(f"ğŸ“œ [Prompt] é€å…¥ LLM:\n{formatted_prompt[:500]}...")

        if model_type == "cloud":
            try:
                answer = AzureLlamaAPI.ask(formatted_prompt)
                print(f"ğŸ¤– [é›²ç«¯ LLM å›æ‡‰] {answer[:300]}...")
            except Exception as e:
                print(f"âŒ [é›²ç«¯ LLM éŒ¯èª¤] {str(e)}")
                answer = "âš ï¸ é›²ç«¯ LLM ä¼ºæœå™¨éŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

        elif model_type == "local":
            try:
                llm = Ollama(model="openchat:latest")
                answer = llm.invoke(formatted_prompt)
                print(f"ğŸ¤– [æœ¬åœ° LLM å›æ‡‰] {answer[:300]}...")
            except Exception as e:
                print(f"âŒ [æœ¬åœ° LLM éŒ¯èª¤] {str(e)}")
                answer = "âš ï¸ æœ¬åœ° LLM ç„¡æ³•é‹è¡Œï¼Œè«‹æª¢æŸ¥è¨­ç½®ã€‚"

        else:
            return Response({"error": "Invalid model_type"}, status=status.HTTP_400_BAD_REQUEST)

        return Response({
            "query": query,
            "answer": answer,
            "retrieved_docs": retrieved_docs if use_retrieval else []
        }, status=status.HTTP_200_OK)