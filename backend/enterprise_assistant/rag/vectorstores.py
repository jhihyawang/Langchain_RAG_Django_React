from rest_framework import generics, status
from rest_framework.views import APIView
from rest_framework.response import Response
from django.shortcuts import get_object_or_404
from ..models import Knowledge
import os
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
import pdfplumber
import pytesseract
import docx
import PyPDF2
from pdf2image import convert_from_path

# è¨­å®šè©åµŒå…¥æ¨¡å‹
embedder = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# è¨­å®šä¼æ¥­å…§éƒ¨çŸ¥è­˜åº«çš„å„²å­˜è·¯å¾‘
CHROMA_ENTERPRISE_DB_PATH = "chroma_enterprise_db"

# åˆå§‹åŒ–å‘é‡è³‡æ–™åº«
enterprise_vectorstore = Chroma(persist_directory=CHROMA_ENTERPRISE_DB_PATH, embedding_function=embedder)

# æ–‡å­—åˆ†å‰²å™¨
text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=128)

def extract_text_from_file(file_path):
    text = ""
    if file_path.endswith(".pdf"):
        with pdfplumber.open(file_path) as pdf:
            text = "\n".join([page.extract_text() for page in pdf.pages if page.extract_text()])
        if not text.strip():
            with open(file_path, "rb") as f:
                reader = PyPDF2.PdfReader(f)
                for page in reader.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
        if not text.strip():
            images = convert_from_path(file_path)
            for img in images:
                text += pytesseract.image_to_string(img, lang="chi_tra") + "\n"
    elif file_path.endswith(".docx"):
        doc = docx.Document(file_path)
        for para in doc.paragraphs:
            text += para.text + "\n"
    print("è§£æå…§å®¹å‰ 500 å­—:", text[:500])
    return text.strip()

def extract_text_from_pdf_with_pages(file_path):
    extracted_pages = []
    with pdfplumber.open(file_path) as pdf:
        for i, page in enumerate(pdf.pages, start=1):
            text = page.extract_text()
            if text:
                extracted_pages.append((i, text))
    if not extracted_pages:
        with open(file_path, "rb") as f:
            reader = PyPDF2.PdfReader(f)
            for i, page in enumerate(reader.pages, start=1):
                page_text = page.extract_text()
                if page_text:
                    extracted_pages.append((i, page_text))
    print(f"âœ… è§£æ {len(extracted_pages)} é  PDF å…§å®¹")
    return extracted_pages

def add_to_enterprise_vectorstore(title, content, page_number=1, knowledge_id=None):
    if not content.strip():
        print(f"âš ï¸ è·³éå­˜å…¥ä¼æ¥­çŸ¥è­˜åº«ï¼ˆå…§å®¹ç‚ºç©ºï¼‰ï¼š{title}")
        return False
    chunks = text_splitter.split_text(content)
    if not chunks:
        print(f"âš ï¸ ç„¡æ³•æ‹†åˆ†æ–‡æœ¬ï¼Œè·³éå­˜å…¥ ChromaDBï¼ˆ{title}ï¼‰")
        return False
    metadata = [
        {
            "title": title,
            "chunk_index": i,
            "page_number": page_number,
            "knowledge_id": knowledge_id
        } for i in range(len(chunks))
    ]
    enterprise_vectorstore.add_texts(chunks, metadatas=metadata)
    print(f"âœ… ä¼æ¥­çŸ¥è­˜åº«å·²æ–°å¢: {title}ï¼Œå…± {len(chunks)} æ®µè½ (Page {page_number})")
    return True

def delete_from_enterprise_vectorstore(knowledge_id):
    try:
        enterprise_vectorstore._collection.delete(where={"knowledge_id": knowledge_id})
        print(f"âœ… å·²åˆªé™¤ knowledge_id={knowledge_id} çš„å‘é‡è³‡æ–™")
        return True
    except Exception as e:
        print(f"âŒ åˆªé™¤å‘é‡è³‡æ–™å¤±æ•—: {e}")
        return False

def list_from_enterprise_vectorstore(knowledge_id):
    try:
        results = enterprise_vectorstore._collection.get(
            where={"knowledge_id": knowledge_id},
            include=["documents", "metadatas"]
        )
        documents = results.get("documents", [])
        metadatas = results.get("metadatas", [])
        ids = results.get("ids", [])
        if not documents:
            print(f"âš ï¸ æœªæ‰¾åˆ° knowledge_id={knowledge_id} çš„å‘é‡è³‡æ–™")
            return []
        chunks = []
        for i in range(len(documents)):
            metadata = metadatas[i] if i < len(metadatas) else {}
            chunks.append({
                "id": ids[i],
                "chunk_index": metadata.get("chunk_index", i),
                "page_number": metadata.get("page_number", None),
                "content": documents[i]
            })
        print(f"âœ… æ‰¾åˆ° {len(chunks)} ç­† knowledge_id={knowledge_id} çš„ chunks")
        return chunks
    except Exception as e:
        print(f"âŒ æŸ¥è©¢ knowledge_id={knowledge_id} çš„å‘é‡è³‡æ–™å¤±æ•—: {e}")
        return []

class ChunkListCreateView(APIView):
    def get(self, request, pk):
        knowledge = get_object_or_404(Knowledge, pk=pk)
        chunks = list_from_enterprise_vectorstore(knowledge.id)
        return Response({
            "knowledge_id": knowledge.id,
            "title": os.path.basename(knowledge.file.name) if knowledge.file else "",
            "chunks": chunks
        }, status=status.HTTP_200_OK)

class ChunkDetailView(APIView):
    """
    - `PUT` æ›´æ–°å–®ä¸€ chunk
    - `DELETE` åˆªé™¤å–®ä¸€ chunk
    """

    def put(self, request, chunk_id):
        content = request.data.get("content")
        if not content:
            return Response({"error": "è«‹æä¾›æ–°çš„ content"}, status=status.HTTP_400_BAD_REQUEST)

        try:
            # æŸ¥å‡ºåŸ metadata
            existing = enterprise_vectorstore._collection.get(
                ids=[chunk_id],
                include=["metadatas"]
            )

            if not existing["metadatas"]:
                return Response({"error": "æ‰¾ä¸åˆ° chunk"}, status=status.HTTP_404_NOT_FOUND)

            metadata = existing["metadatas"][0]

            # åˆªé™¤èˆŠçš„å‘é‡
            enterprise_vectorstore._collection.delete(ids=[chunk_id])

            # åŠ å…¥æ–°çš„å‘é‡ï¼ˆæ–°å…§å®¹ + èˆŠ metadataï¼‰
            enterprise_vectorstore.add_texts(
                [content],
                metadatas=[metadata]
            )

            # å˜—è©¦æ›´æ–° Knowledge çš„ updated_at æ™‚é–“
            knowledge_id = metadata.get("knowledge_id")
            if knowledge_id:
                from ..models import Knowledge  # é¿å…å¾ªç’° import å•é¡Œ
                from django.utils.timezone import now

                try:
                    knowledge = Knowledge.objects.get(id=knowledge_id)
                    # æ›´æ–° vectorstore å¾Œï¼Œé‡æ–°å–å¾—ç¬¬ä¸€å€‹ chunk ç•¶ä½œ content
                    chunks = list_from_enterprise_vectorstore(knowledge.id)
                    first_chunk = chunks[0]["content"] if chunks else ""
                    knowledge.content = first_chunk
                    knowledge.updated_at = now()
                    knowledge.chunk = len(chunks)
                    knowledge.save(update_fields=["content", "chunk", "updated_at"])
                    print(f"ğŸ“Œ å·²åŒæ­¥æ›´æ–° Knowledge ID={knowledge_id} çš„ä¿®æ”¹æ™‚é–“")
                except Knowledge.DoesNotExist:
                    print(f"âš ï¸ ç„¡æ³•æ‰¾åˆ° Knowledge ID={knowledge_id}ï¼Œç„¡æ³•åŒæ­¥æ™‚é–“")

            return Response({"message": "âœ… å·²æ›´æ–° chunk"}, status=status.HTTP_200_OK)

        except Exception as e:
            return Response({"error": f"æ›´æ–°å¤±æ•—ï¼š{str(e)}"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def delete(self, request, chunk_id):
        try:
            # å…ˆå–å¾— metadataï¼ˆå¯é¸ï¼Œç´”ç²¹ç‚ºäº† logï¼‰
            metadata = enterprise_vectorstore._collection.get(
                ids=[chunk_id],
                include=["metadatas"]
            ).get("metadatas", [{}])[0]

            knowledge_id = metadata.get("knowledge_id", "æœªçŸ¥")
            enterprise_vectorstore._collection.delete(ids=[chunk_id])
            print(f"ğŸ—‘ å·²åˆªé™¤ chunkï¼ˆID: {chunk_id}, knowledge_id: {knowledge_id}ï¼‰")

            return Response({"message": "âœ… å·²åˆªé™¤ chunk"}, status=status.HTTP_204_NO_CONTENT)

        except Exception as e:
            return Response({"error": f"åˆªé™¤å¤±æ•—ï¼š{str(e)}"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
