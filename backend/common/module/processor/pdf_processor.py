import os
import re
import time
from datetime import datetime

import fitz  # PyMuPDF
import numpy as np
import ollama
import pdfplumber
import torch
from easyocr import Reader
from pdf2image import convert_from_path
from PIL import Image
from transformers import AutoModelForObjectDetection, AutoProcessor


def log(msg):
    now = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
    print(f"{now} {msg}")

class PdfProcessor:
    def __init__(self, pdf_path, output_dir="media/extract_data", model_name="gemma3:27b", knowledge_id=None, vectorstore=None,cid_threshold=20):
        self.pdf_path = pdf_path
        self.file_stem = os.path.splitext(os.path.basename(pdf_path))[0]
        self.output_dir = os.path.join(output_dir, self.file_stem)
        self.model_name = model_name
        self.knowledge_id = knowledge_id
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.reader = Reader(['ch_tra', 'en'], gpu=torch.cuda.is_available())
        self.detector = AutoModelForObjectDetection.from_pretrained("microsoft/table-transformer-detection", revision="no_timm").to(self.device)
        self.processor = AutoProcessor.from_pretrained("microsoft/table-transformer-detection", revision="no_timm")
        self.cid_threshold = cid_threshold
        #self.vectorstore = vectorstore or VectorStoreHandler(db_path="chroma_user_db")

        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, "images"), exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, "tables"), exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, "ocr_fallback"), exist_ok=True)

    # def should_ocr(self, text):
    #     cid_count = text.count("(cid:")
    #     return cid_count > 15 or (len(text) > 0 and cid_count / len(text) > 0.3) or not bool(re.search(r"[\u4e00-\u9fa5a-zA-Z]", text))

    def should_ocr(self, text):
        cid_unicode_count = len(re.findall(r'[\ue000-\uf8ff]', text))
        cid_marker_count = len(re.findall(r'\(cid:\d+\)', text))
        cid_count = cid_unicode_count + cid_marker_count
        if cid_count >= self.cid_threshold:
                print(f"CID é” {cid_count}ï¼Œä½¿ç”¨ OCR å¿«å–")
        return True

    def summarize_image(self, image_paths, prompt):
        if isinstance(image_paths, str):
            image_paths = [image_paths]
        log("[è§£æåœ–ç‰‡æˆ–æ•´é å½±åƒ]")
        system_prompt = "ä½ æ˜¯ä¸€ä½é‡å°åœ–ç‰‡å½±åƒå’Œè¡¨æ ¼å½±åƒé€²è¡Œæå–å…§å®¹çš„åŠ©æ‰‹ï¼Œè«‹ä»¥æ•˜è¿°è€…çš„è§’åº¦èªªæ˜æ¯å¼µåœ–ç‰‡ä¸­çš„è³‡æ–™æˆ–æ–‡æœ¬å…§å®¹ï¼Œä¾‹å¦‚æ•¸æ“šã€æ–‡å­—ç­‰ï¼Œè‹¥æ˜¯åœ–è¡¨ä¹Ÿè«‹èªªæ˜å…¶è¶¨å‹¢èˆ‡é—œéµæ•¸æ“š"
        try:
            response = ollama.chat(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt, "images": image_paths}
                ]
            )
            return response['message']['content']
        except Exception as e:
            return f"âŒ åœ–åƒåˆ†æéŒ¯èª¤: {str(e)}"

    def detect_rotation_angle_easyocr(self, ocr_result, min_text_count=5, vertical_angle_range=(75, 105)):
        vertical_texts, short_texts, tall_boxes = 0, 0, 0
        total_texts = len(ocr_result)
        for (box, text, _) in ocr_result:
            x0, y0 = box[0]; x1, y1 = box[1]
            dx, dy = x1 - x0, y1 - y0
            angle = abs(np.arctan2(dy, dx) * 180 / np.pi)
            if vertical_angle_range[0] <= angle <= vertical_angle_range[1]: vertical_texts += 1
            if len(text.strip()) <= 1: short_texts += 1
            w = np.linalg.norm(np.array(box[0]) - np.array(box[1]))
            h = np.linalg.norm(np.array(box[0]) - np.array(box[3]))
            if h > w * 2: tall_boxes += 1
        if total_texts < min_text_count: return 0
        if vertical_texts / total_texts > 0.5 or short_texts / total_texts > 0.4 or tall_boxes / total_texts > 0.4:
            return 90
        return 0

    def get_title_from_above(self, image_path):
        with Image.open(image_path) as img:
            w, h = img.size
            crop = img.crop((0, 0, w, min(80, h)))
            result = self.reader.readtext(np.array(crop))
            return result[0][1] if result else "ç„¡æ¨™é¡Œ"

    def rotate_original_pdf(self, file_path, rotated_pages):
        log("rotate this file")
        doc = fitz.open(file_path)
        for page_index in rotated_pages:
            page = doc[page_index - 1]
            page.set_rotation((page.rotation + 90) % 360)
            log(f"========== Page {page_index} has been rotated 90 degrees ==========")

        temp_path = file_path + ".rotated.pdf"
        doc.save(temp_path)
        doc.close()
        os.replace(temp_path, file_path)
        return file_path

    def process(self):
        start_time = time.time()
        text_results, table_results, image_results = [], [], []
        table_pages = []
        page_images = convert_from_path(self.pdf_path)
        doc = fitz.open(self.pdf_path)

        with pdfplumber.open(self.pdf_path) as pdf:
            for i, page in enumerate(pdf.pages, start=1):
                log(f"ğŸ” è™•ç†ç¬¬ {i} é ...")
                if page.extract_tables():
                    table_pages.append(i)
                    continue

                text = page.extract_text() or ""
                if self.should_ocr(text):
                    path = os.path.join(self.output_dir, "ocr_fallback", f"page_{i}.png")
                    img = page_images[i - 1]
                    img.save(path)
                    ocr_result = self.reader.readtext(np.array(img))
                    ocr_text = "\n".join([text for _, text, conf in ocr_result if conf > 0.5]) if ocr_result else ""
                    print(f"==========extract text from page {page}==========\n {ocr_text.strip()}")
                    prompt = f"ä»¥ä¸‹åœ–ç‰‡æ˜¯ä¸€é PDFæ–‡ä»¶çš„åŸå§‹å…§å®¹å’Œæ“·å–çš„æ–‡å­—å¦‚ä¸‹:{ocr_text.strip()}ï¼Œè«‹ç›´æ¥æ•˜è¿°å…§å®¹é‡é»ï¼Œæ¢åˆ—å…¶é‚è¼¯èˆ‡æ®µè½ï¼Œå‹¿åŠ å…¥å¤šé¤˜å¼•è¨€æˆ–è©•è«–"
                    summary = self.summarize_image(path, prompt)
                    log(f"ğŸ“ ç¬¬ {i} é æ–‡å­—æ‘˜è¦å®Œæˆï¼š{summary[:80]}...")
                    #self.vectorstore.add(summary, media_type="text", page=i, document_id=self.knowledge_id, source=path)
                    text_results.append({
                        "page": i,
                        "source": "llm",
                        "content": summary
                    })
                else:
                    #self.vectorstore.add("[æ–‡å­—]" + text, media_type="text", page=i, document_id=self.knowledge_id, source="text")
                    log(f"ğŸ“ ç¬¬ {i} é ç´”æ–‡å­—è™•ç†å®Œæˆï¼š{text[:80]}...")
                    text_results.append({
                        "page": i,
                        "source": "llm",
                        "content": text
                    })

                fitz_page = doc.load_page(i - 1)
                for img_index, img in enumerate(fitz_page.get_images(full=True)):
                    xref = img[0]
                    base = doc.extract_image(xref)
                    img_path = os.path.join(self.output_dir, "images", f"page{i}_img{img_index+1}.{base['ext']}")
                    with open(img_path, "wb") as f: f.write(base["image"])
                    prompt = "è«‹æè¿°åœ–ç‰‡å…§å®¹ï¼Œè‹¥ç‚ºåœ–è¡¨è«‹æŒ‡å‡ºé¡å‹ã€X/Yè»¸æ„ç¾©ã€è¶¨å‹¢èˆ‡é—œéµè®ŠåŒ–ï¼Œè‹¥éåœ–è¡¨è«‹æè¿°ä¸»è¦æ§‹æˆèˆ‡é‡è¦è³‡è¨Š"
                    summary = self.summarize_image(img_path, prompt)
                    log(f"ğŸ–¼ï¸ ç¬¬ {i} é åœ–ç‰‡æ‘˜è¦å®Œæˆï¼š{summary[:80]}...")
                    #self.vectorstore.add("[åœ–ç‰‡]" + summary, media_type="image", page=i, document_id=self.knowledge_id, source=img_path)
                    image_results.append({
                        "page": i,
                        "source": f"images/page{i}_img{img_index+1}.{base['ext']}",
                        "content": summary
                    })

        table_blocks = []
        rotated_pages = []
        for i in table_pages:
            log(f"ğŸ“„ æª¢æŸ¥è¡¨æ ¼é ç¬¬ {i} é æ—‹è½‰èˆ‡åµæ¸¬...")
            img = page_images[i - 1]
            ocr_result = self.reader.readtext(np.array(img))
            angle = self.detect_rotation_angle_easyocr(ocr_result)
            if angle == 90:
                img = img.rotate(-90, expand=True)
                page_images[i - 1] = img
                rotated_pages.append(i)

            inputs = self.processor(images=img, return_tensors="pt").to(self.device)
            with torch.no_grad():
                outputs = self.detector(**inputs)
            target_sizes = torch.tensor([img.size[::-1]]).to(self.device)
            results = self.processor.post_process_object_detection(outputs, threshold=0.6, target_sizes=target_sizes)[0]

            for j, box in enumerate(results["boxes"]):
                coords = box.tolist()  # [x1, y1, x2, y2]
                cropped = img.crop(coords)
                path = os.path.join(self.output_dir, "tables", f"page{i}_table{j+1}.png")
                cropped.save(path)
                ocr = self.reader.readtext(np.array(cropped))
                merged = "\n".join([r[1] for r in ocr])
                box_width = coords[2] - coords[0]
                table_blocks.append({
                    "page": i,
                    "image": path,
                    "ocr_text": merged,
                    "box_width": box_width
                })
        table_blocks.sort(key=lambda x: x["page"])
        grouped, temp = [], [table_blocks[0]] if table_blocks else []

        for i in range(1, len(table_blocks)):
            prev, curr = table_blocks[i-1], table_blocks[i]
            if (
                curr["page"] == prev["page"] + 1
                and abs(curr["box_width"] - prev["box_width"]) / max(prev["box_width"], 1) < 0.1
            ):
                temp.append(curr)
            else:
                grouped.append(temp)
                temp = [curr]

        for group_index, group in enumerate(grouped):
            texts = [g["ocr_text"] for g in group]
            imgs = [g["image"] for g in group]
            pages = [g["page"] for g in group]
            title = self.get_title_from_above(imgs[0])
            prompt = (
                f"ä»¥ä¸‹æ˜¯è¡¨æ ¼æ¨™é¡Œï¼š{title}\nä»¥ä¸‹æ˜¯ OCR å…§å®¹ï¼š\n{chr(10).join(texts)}\n"
                f"è«‹çµ±æ•´æ‘˜è¦å¦‚ä¸‹ï¼š\n1. è¡¨æ ¼ä¸»é¡Œ\n2. æ¯å€‹æ¬„ä½çš„æ„ç¾©\n3. æ•¸æ“šè¶¨å‹¢èˆ‡é‡é»"
            )
            summary = self.summarize_image(imgs, prompt)
            log(f"ğŸ“‹ è¡¨æ ¼çµ„ {group_index + 1} æ‘˜è¦å®Œæˆï¼š{summary[:80]}...")
            #table_results.append(summary)
            table_results.append({
                "page": pages,
                "source": imgs ,
                "title": title,
                "content": f"[ocr]\n{chr(10).join(texts)}\n[llmæ‘˜è¦]\n{summary}"
            })

        if rotated_pages:
            self.rotate_original_pdf(self.pdf_path, rotated_pages)

        end_time = time.time()
        log(f"âœ… PDF å…¨éƒ¨è™•ç†å®Œæˆï¼Œç”¨æ™‚ {end_time - start_time:.2f} ç§’")

        return {"text": text_results, "table": table_results, "image": image_results}
    
    # åŸå…ˆä½¿ç”¨ table-transformer çš„è¡¨æ ¼åµæ¸¬æµç¨‹ï¼Œæ”¹ç‚ºä½¿ç”¨ pdfplumber çš„ page.find_tables()
    # ä¸¦ä¸”åƒ…åœ¨éœ€è¦è™•ç†åœ–ç‰‡æ‘˜è¦çš„æƒ…å¢ƒä¸‹æ‰ä½¿ç”¨ convert_from_path
    def optimized_process(self):
        import time
        start_time = time.time()
        text_results, table_results, image_results = [], [], []
        table_pages = []

        doc = fitz.open(self.pdf_path)
        pdf = pdfplumber.open(self.pdf_path)

        page_images = []  # å»¶å¾Œè½‰æ›åœ–ç‰‡
        need_page_image = set()

        for i, page in enumerate(pdf.pages, start=1):
            log(f"ğŸ” è™•ç†ç¬¬ {i} é ...")

            text = page.extract_text() or ""
            if page.extract_tables():
                table_pages.append(i)
                need_page_image.add(i)

            if self.should_ocr(text):
                need_page_image.add(i)

            if doc[i - 1].get_images(full=True):
                need_page_image.add(i)

        # åªè½‰æ›éœ€è¦çš„é é¢åœ–ç‰‡
        if need_page_image:
            log(f"ğŸ–¼ï¸ convert_from_path è½‰æ›é é¢: {sorted(need_page_image)}")
            page_images_all = convert_from_path(self.pdf_path)
            page_images = {
                i: page_images_all[i - 1] for i in need_page_image
            }

        # è™•ç†ç´”æ–‡å­— + åœ–ç‰‡
        for i, page in enumerate(pdf.pages, start=1):
            text = page.extract_text() or ""

            if i in table_pages:
                continue

            if self.should_ocr(text):
                img = page_images[i]
                path = os.path.join(self.output_dir, "ocr_fallback", f"page_{i}.png")
                img.save(path)
                ocr_result = self.reader.readtext(np.array(img))
                ocr_text = "\n".join([text for _, text, conf in ocr_result if conf > 0.5]) if ocr_result else ""
                prompt = f"ä»¥ä¸‹åœ–ç‰‡æ˜¯ä¸€é PDFæ–‡ä»¶çš„åŸå§‹å…§å®¹å’Œæ“·å–çš„æ–‡å­—å¦‚ä¸‹:{ocr_text.strip()}ï¼Œè«‹ç›´æ¥æ•˜è¿°å…§å®¹é‡é»ï¼Œæ¢åˆ—å…¶é‚è¼¯èˆ‡æ®µè½ï¼Œå‹¿åŠ å…¥å¤šé¤˜å¼•è¨€æˆ–è©•è«–"
                summary = self.summarize_image(path, prompt)
                log(f"ğŸ“ ç¬¬ {i} é æ–‡å­—æ‘˜è¦å®Œæˆï¼š{summary[:80]}...")
                text_results.append({
                    "page": i,
                    "source": "ocr+llm",
                    "content": f"[ocr]{ocr_text.strip()}\n[llm]{summary}"
                })
            else:
                log(f"ğŸ“ ç¬¬ {i} é ç´”æ–‡å­—è™•ç†å®Œæˆï¼š{text[:80]}...")
                text_results.append({
                    "page": i,
                    "source": "ori",
                    "content": text
                })

            fitz_page = doc.load_page(i - 1)
            for img_index, img in enumerate(fitz_page.get_images(full=True)):
                xref = img[0]
                base = doc.extract_image(xref)
                img_path = os.path.join(self.output_dir, "images", f"page{i}_img{img_index+1}.{base['ext']}")
                with open(img_path, "wb") as f:
                    f.write(base["image"])
                prompt = "è«‹æè¿°åœ–ç‰‡å…§å®¹ï¼Œè‹¥ç‚ºåœ–è¡¨è«‹æŒ‡å‡ºé¡å‹ã€X/Yè»¸æ„ç¾©ã€è¶¨å‹¢èˆ‡é—œéµè®ŠåŒ–ï¼Œè‹¥éåœ–è¡¨è«‹æè¿°ä¸»è¦æ§‹æˆèˆ‡é‡è¦è³‡è¨Š"
                summary = self.summarize_image(img_path, prompt)
                log(f"ğŸ–¼ï¸ ç¬¬ {i} é åœ–ç‰‡æ‘˜è¦å®Œæˆï¼š{summary[:80]}...")
                image_results.append({
                    "page": i,
                    "source": f"images/page{i}_img{img_index+1}.{base['ext']}",
                    "content": summary
                })

        # è™•ç†è¡¨æ ¼é 
        table_blocks = []
        rotated_pages = []
        for i in table_pages:
            log(f"ğŸ“„ æª¢æŸ¥ç¬¬ {i} é è¡¨æ ¼ä½ç½®...")
            img = page_images[i]
            page = pdf.pages[i - 1]

            ocr_result = self.reader.readtext(np.array(img))
            angle = self.detect_rotation_angle_easyocr(ocr_result)
            if angle == 90:
                img = img.rotate(-90, expand=True)
                page_images[i] = img
                rotated_pages.append(i)

            tables = page.find_tables()
            for j, table in enumerate(tables):
                bbox = table.bbox  # (x0, top, x1, bottom)
                cropped = img.crop(bbox)
                path = os.path.join(self.output_dir, "tables", f"page{i}_table{j+1}.png")
                cropped.save(path)
                ocr = self.reader.readtext(np.array(cropped))
                merged = "\n".join([r[1] for r in ocr])
                box_width = bbox[2] - bbox[0]
                table_blocks.append({
                    "page": i,
                    "image": path,
                    "ocr_text": merged,
                    "box_width": box_width
                })

        # è¡¨æ ¼ç¾¤çµ„é‚è¼¯
        table_blocks.sort(key=lambda x: x["page"])
        grouped, temp = [], [table_blocks[0]] if table_blocks else []

        for i in range(1, len(table_blocks)):
            print("===== groping table =====")
            prev, curr = table_blocks[i-1], table_blocks[i]
            if (
                curr["page"] == prev["page"] + 1
                and abs(curr["box_width"] - prev["box_width"]) / max(prev["box_width"], 1) < 0.1
            ):
                temp.append(curr)
            else:
                grouped.append(temp)
                temp = [curr]
        if temp: grouped.append(temp)

        for group_index, group in enumerate(grouped):
            texts = [g["ocr_text"] for g in group]
            imgs = [g["image"] for g in group]
            pages = [g["page"] for g in group]
            title = self.get_title_from_above(imgs[0])
            print(f"Title: {title}")
            print(f"OCR: {texts}")
            prompt = (
                f"ä»¥ä¸‹æ˜¯è¡¨æ ¼æ¨™é¡Œï¼š{title}\nä»¥ä¸‹æ˜¯ OCR å…§å®¹ï¼š\n{chr(10).join(texts)}\n"
                f"è«‹çµ±æ•´æ‘˜è¦å¦‚ä¸‹ï¼š\n1. è¡¨æ ¼ä¸»é¡Œ\n2. æ¯å€‹æ¬„ä½çš„æ„ç¾©\n3. æ•¸æ“šè¶¨å‹¢èˆ‡é‡é»"
            )
            summary = self.summarize_image(imgs, prompt)
            log(f"ğŸ“‹ è¡¨æ ¼çµ„ {group_index + 1} æ‘˜è¦å®Œæˆï¼š{summary[:80]}...")
            table_results.append({
                "page": pages,
                "source": imgs,
                "title": title,
                "content": f"[ocr]\n{chr(10).join(texts)}\n[llmæ‘˜è¦]\n{summary}"
            })

        if rotated_pages:
            self.rotate_original_pdf(self.pdf_path, rotated_pages)

        pdf.close()
        end_time = time.time()
        log(f"âœ… PDF å…¨éƒ¨è™•ç†å®Œæˆï¼Œç”¨æ™‚ {end_time - start_time:.2f} ç§’")

        return {"text": text_results, "table": table_results, "image": image_results}



if __name__ == "__main__":
    processor = PdfProcessor("test.pdf")
    result = processor.optimized_process()
