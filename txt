import io
import json
import os
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

import fitz  # PyMuPDF
import numpy as np
import ollama
import pdfplumber
import torch
from easyocr import Reader
from PIL import Image
from transformers import AutoModelForObjectDetection, AutoProcessor

from common.modules.processor.vector_store import VectorStoreHandler


def log(msg):
    now = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
    print(f"{now} {msg}")

class PdfProcessor:
    def __init__(self, pdf_path, vectorstore="chroma_user_db", output_dir="media",
                 model_name="gemma3:12b", knowledge_id=None, knowledge_title="æœªçŸ¥æ–‡ä»¶",
                 cid_threshold=20):
        self.pdf_path = pdf_path
        self.file_stem = os.path.splitext(os.path.basename(pdf_path))[0]
        self.output_dir = os.path.join(output_dir, "extract_data", self.file_stem)
        self.model_name = model_name
        self.knowledge_id = knowledge_id
        self.knowledge_title = knowledge_title
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.cid_threshold = cid_threshold
        self.dpi = 200

        # OCRã€æª¢æ¸¬å™¨ã€å‘é‡åº«
        self.reader = Reader(['ch_tra', 'en'], gpu=torch.cuda.is_available())
        self.detector = AutoModelForObjectDetection.from_pretrained(
            "microsoft/table-transformer-detection", revision="no_timm"
        ).to(self.device)
        self.processor = AutoProcessor.from_pretrained(
            "microsoft/table-transformer-detection", revision="no_timm"
        )
        self.vectorstore = VectorStoreHandler(db_path=vectorstore)

        # å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾
        os.makedirs(self.output_dir, exist_ok=True)
        for sub in ("images", "tables", "ocr_fallback"):
            os.makedirs(os.path.join(self.output_dir, sub), exist_ok=True)

    def should_ocr(self, text):
        cid_unicode_count = len(re.findall(r'[\ue000-\uf8ff]', text))
        cid_marker_count = len(re.findall(r'\(cid:\d+\)', text))
        cid_count = cid_unicode_count + cid_marker_count
        if cid_count >= self.cid_threshold:
            print(f"CID é” {cid_count}ï¼Œä½¿ç”¨ OCR å¿«å–")
            return True
        else:
            print(f"æ–‡å­—ç¬¦åˆæ¨™æº–ï¼Œä½¿ç”¨pdfplumber")
            return False
        
    def summarize_image(self, image_paths, prompt):
        if isinstance(image_paths, str):
            image_paths = [image_paths]
        log("[è§£æåœ–ç‰‡æˆ–æ•´é å½±åƒ]")
        system_prompt = (
            "ä½ æ˜¯ä¸€ä½é‡å°åœ–ç‰‡å½±åƒå’Œè¡¨æ ¼å½±åƒé€²è¡Œæå–å…§å®¹çš„åŠ©æ‰‹"
            "è«‹é‚„åŸæ¯å¼µåœ–ç‰‡ä¸­çš„æ–‡å­—æ®µè½ã€è¡¨æ ¼å…§å®¹"
            "å¦‚æœæœ‰æä¾›ocrçš„æ–‡å­—è¾¨è­˜çµæœä¹Ÿå¯ä»¥åƒè€ƒï¼Œæ–‡å­—è¾¨è­˜å¯èƒ½æœ‰éŒ¯èª¤ï¼Œè‹¥å­—è©ä¸åˆé‚è¼¯å¿…é ˆè½‰æ›æˆæ­£å¸¸çš„å­—è©"
            "è‹¥æ˜¯åœ–è¡¨å®Œæ•´å›å‚³æ¯ç­†è³‡æ–™å’Œå…¶è¶¨å‹¢"
            "è‹¥æ˜¯è¡¨æ ¼å…§å®¹ç”¨markdownè¡¨æ ¼æ ¼å¼å›å‚³çµæœ"
        )
        try:
            rsp = ollama.chat(
                model=self.model_name,
                messages=[
                    {"role":"system","content":system_prompt},
                    {"role":"user","content":prompt,"images":image_paths}
                ]
            )
            return rsp['message']['content']
        except Exception as e:
            return f"âŒ åœ–åƒåˆ†æéŒ¯èª¤: {e}"
 
    def detect_rotation_angle_easyocr(self, ocr_result, min_text_count=5, vertical_angle_range=(75, 105)):
        vertical_texts, short_texts, tall_boxes = 0, 0, 0
        total_texts = len(ocr_result)
        for (box, text, _) in ocr_result:
            x0, y0 = box[0]; x1, y1 = box[1]
            dx, dy = x1 - x0, y1 - y0
            angle = abs(np.arctan2(dy, dx) * 180 / np.pi)
            if vertical_angle_range[0] <= angle <= vertical_angle_range[1]: vertical_texts += 1
            if len(text.strip()) <= 1: short_texts += 1
            w = np.linalg.norm(np.array(box[0]) - np.array(box[1]))
            h = np.linalg.norm(np.array(box[0]) - np.array(box[3]))
            if h > w * 2: tall_boxes += 1
        if total_texts < min_text_count: return 0
        if vertical_texts / total_texts > 0.5 or short_texts / total_texts > 0.4 or tall_boxes / total_texts > 0.4:
            return 90
        return 0
    
    def calculate_table_area(self,box) -> float:
        x1, y1, x2, y2 = box
        total_table_area = abs((x2 - x1) * (y2 - y1))
        return total_table_area
        
    def extract_table(self, img, page_num, idx, box):
        try:
            x1, y1, x2, y2 = box.tolist()
            # 1. è¨ˆç®—åˆ‡å‰²ç¯„åœ
            left = max(0, x1-50)
            top  = max(0, y1-40)
            right= min(img.width, x2+50)
            bottom=min(img.height,y2+50)
            cropped = img.crop((left, top, right, bottom))
            
            # 2. ä¿å­˜æˆªå›¾
            path = os.path.join(self.output_dir, "tables", f"page{page_num}_table{idx+1}.png")
            cropped.save(path)

            # 3. OCR å¹¶è¿‡æ»¤ä½ç½®ä¿¡åº¦æ–‡å­—
            ocr_results = self.reader.readtext(np.array(cropped))
            texts = [txt for _, txt, conf in ocr_results if conf > 0.5]
            merged = "\r\n".join(texts)
            
            # 4. è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦
            prompt = (
                f"ä»¥ä¸‹æ˜¯ä¸€å¼µè¡¨æ ¼æˆªåœ–ï¼ŒOCR å‡ºä¾†çš„æ–‡å­—ç‚ºï¼š\n{merged}\n"
                "è«‹æ ¹æ“šæˆªåœ–å’Œæ–‡å­—é‚„åŸè¡¨æ ¼çµæ§‹ï¼Œç”¨ markdown è¡¨æ ¼æ ¼å¼å›å‚³ç´”å…§å®¹ã€‚"
            )
            summary = self.summarize_image(path, prompt)

            result = {
                "page": page_num,
                "media_type": "table",
                "source": path,
                "content": summary
            }
            return result
        
        except Exception as e:
            # è®°å½•å‡ºé”™é¡µç ä¸ç´¢å¼•ï¼Œè¿”å›ä¸€ä¸ªé”™è¯¯æ ‡è¯†çš„ç»“æœä»¥ä¿è¯æµç¨‹ä¸ä¸­æ–­
            log(f"âŒ ç¬¬ {page_num} é¡µç¬¬ {idx+1} ä¸ªè¡¨æ ¼æå–å¼‚å¸¸ï¼š{e}")
            
            return {
                "page": page_num,
                "media_type": "table",
                "source": None,
                "content": f"âŒ è¡¨æ ¼æå–å¤±è´¥ï¼š{e}"
            }
            
    def extract_texts(self, page, page_num, img=None):
        try:
            text = page.extract_text() or ""
            if self.should_ocr(text) and img is not None:
                # OCR è·¯å¾„åˆ†æ”¯
                path = os.path.join(self.output_dir, "ocr_fallback", f"page_{page_num}.png")
                img.save(path)
                ocr_results = self.reader.readtext(np.array(img))
                # è¿‡æ»¤ç½®ä¿¡åº¦
                texts = [t for _, t, conf in ocr_results if conf > 0.5]
                merged = "\r\n".join(texts) if texts else ""
                prompt = (
                    f"ä»¥ä¸‹åœ–ç‰‡æ˜¯ä¸€é PDFæ–‡ä»¶çš„åŸå§‹å…§å®¹å’Œæ“·å–çš„æ–‡å­—å¦‚ä¸‹ï¼š\n{merged}\n"
                    "è«‹ä»¥åŸå§‹æ–‡å­—å…§å®¹é‡æ§‹é€™æ®µæ–‡å­—æ®µè½ï¼Œé‚„åŸå…¶åŸæ–‡ï¼Œè‹¥æœ‰è¡¨æ ¼è«‹é‚„åŸç‚ºmarkdownè¡¨æ ¼ã€‚"
                )
                summary = self.summarize_image(path, prompt)
                content = f"[ocr]{merged}\n\n[llm]{summary}"
                source  = "ocr+llm"
            else:
                # åŸæ–‡è·¯å¾„åˆ†æ”¯
                content = text
                source  = "ori"

            return {
                "page": page_num,
                "media_type": "text",
                "source": source,
                "content": content
            }

        except Exception as e:
            log(f"âŒ ç¬¬ {page_num} é æ–‡å­—æŠ½å–å¼‚å¸¸ï¼š{e}")
            return {
                "page": page_num,
                "media_type": "text",
                "source": None,
                "content": f"âŒ æ–‡å­—æŠ½å–å¤±è´¥ï¼š{e}"
            }

    def extract_imgs(self, doc, page_num):
        results = []
        try:
            fitz_page = doc.load_page(page_num - 1)
            image_list = fitz_page.get_images(full=True)
            for img_index, img_info in enumerate(image_list):
                xref = img_info[0]
                base = doc.extract_image(xref)
                image_bytes, ext = base["image"], base["ext"]
                img = Image.open(io.BytesIO(image_bytes))
                ocr_results = self.reader.readtext(np.array(img))
                # è¿‡æ»¤ç½®ä¿¡åº¦
                texts = [t for _, t, conf in ocr_results if conf > 0.5]
                merged = "\r\n".join(texts)
                if len(merged) < 10:
                    log(f"âš ï¸ ç¬¬ {page_num} é ç¬¬ {img_index+1} å¼µåœ–ç‰‡ OCR çµæœä¸è¶³ï¼Œè·³é")
                    continue

                path = os.path.join(self.output_dir, "images", f"page_{page_num}_img_{img_index+1}.{ext}")
                img.save(path)

                prompt = (
                    "è«‹æè¿°é€™å¼µåœ–ç‰‡çš„å…§å®¹ã€‚å¦‚æœæ˜¯æ–‡ç« è«‹é‚„åŸæ–‡ç« çš„æ‰€æœ‰æ–‡å­—å…§å®¹ï¼Œå¦‚æœæ˜¯è¡¨æ ¼è¦ç”¨å’Œåœ–ç‰‡ä¸­åŒæ¨£çš„è¡¨æ ¼æ¶æ§‹å‘ˆç¾æ–‡å­—å…§å®¹ä»¥åŠç›¸å°æ‡‰çš„æ¬„ä½ï¼Œä¸¦ç”¨markdownè¡¨æ ¼æ ¼å¼å›å‚³çµæœ"
                    "è«‹ç›´æ¥æè¿°å…§å®¹ï¼Œä¸éœ€è¦ä»»ä½•é–‹å ´ç™½ã€èªªæ˜æˆ–å¼•å°å¥ã€‚"
                    "åƒ…æä¾›ç´”å…§å®¹ï¼Œä¸è¦åŠ ä¸Š:[å¥½çš„]ã€[ä»¥ä¸‹æ˜¯åˆ†æ]ç­‰å­—å¥"
                    "è‹¥åœ–ç‰‡ç‚ºåœ–è¡¨ï¼Œè«‹æŒ‡å‡º:\r\n"
                    "1.åœ–è¡¨é¡å‹(å¦‚æŠ˜ç·šåœ–ã€é•·æ¢åœ–ç­‰)\r\n"
                    "2.Xè»¸å’ŒYè»¸ä»£è¡¨çš„æ„ç¾©\r\n"
                    "3.æ¯ç­†è³‡æ–™çš„æ•¸å€¼å’Œåç¨±\r\n"
                    "4.è³‡æ–™å‘ˆç¾çš„è¶¨å‹¢ã€æœ€é«˜æˆ–æœ€ä½é»ä»¥åŠå…¶é—œéµè®ŠåŒ–\r\n"
                    "è‹¥åœ–ç‰‡éåœ–è¡¨ï¼Œè«‹æ”¹ç‚ºæè¿°å…¶ä¸»è¦æ§‹æˆèˆ‡é‡è¦è³‡è¨Š"
                    )
                summary = self.summarize_image(path, prompt)

                results.append({
                    "page": page_num,
                    "media_type": "image",
                    "source": path,
                    "content": summary
                })

        except Exception as e:
            log(f"âŒ ç¬¬ {page_num} é åœ–ç‰‡æŠ½å–ç•°å¸¸ï¼š{e}")
            results.append({
                "page": page_num,
                "media_type": "image",
                "source": None,
                "content": f"âŒ åœ–ç‰‡æŠ½å–å¤±æ•—ï¼š{e}"
            })

        return results
    
    def process_page(self, i, page, need_img, table_pages):
        """
        è™•ç†å–®é é‚è¼¯ï¼Œè¿”å› (page_results, rotated_pages_for_this_page)
        """
        local_results = []
        local_rotated = []

        # 1. æŒ‰éœ€æ¸²æŸ“
        img = None
        if i in need_img:
            pix = self._doc.load_page(i-1).get_pixmap(dpi=self.dpi)
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

        # 2. è¡¨æ ¼æª¢æ¸¬ & æ—‹è½‰
        if i in table_pages and img:
            ocr_res = self.reader.readtext(np.array(img))
            angle = self.detect_rotation_angle_easyocr(ocr_res)
            if angle == 90:
                img = img.rotate(-90, expand=True)
                local_rotated.append(i)

            inputs = self.processor(images=img, return_tensors="pt").to(self.device)
            with torch.no_grad():
                outputs = self.detector(**inputs)
            target_sizes = torch.tensor([img.size[::-1]]).to(self.device)
            det = self.processor.post_process_object_detection(
                outputs, threshold=0.5, target_sizes=target_sizes
            )[0]

            # ä¾åºæŠ½è¡¨æ ¼
            for idx, box in enumerate(det["boxes"]):
                tbl = self.extract_table(img, i, idx, box)
                local_results.append(tbl)

            # å¦‚æœè¡¨æ ¼ä¸ä½”å¤ªå¤§ï¼Œå†è·‘æ–‡å­—èˆ‡åœ–ç‰‡
            page_area = img.width * img.height
            total_area = sum(abs((x2-x1)*(y2-y1)) for x1,y1,x2,y2 in det["boxes"])
            if total_area / page_area < 0.48:
                local_results.append(self.extract_texts(page, i, img))
                local_results.extend(self.extract_imgs(self._doc, i))
        else:
            # éè¡¨æ ¼é 
            local_results.append(self.extract_texts(page, i, img))
            local_results.extend(self.extract_imgs(self._doc, i))

        return local_results, local_rotated
    
    def optimized_process(self):
        t0 = time.time()
        self._doc = fitz.open(self.pdf_path)
        pdf = pdfplumber.open(self.pdf_path)

        # æ¨™è¨˜
        need_img = set()
        table_pages = []
        for i, p in enumerate(pdf.pages, start=1):
            text = p.extract_text() or ""
            if p.extract_tables():
                table_pages.append(i)
                need_img.add(i)
            if self.should_ocr(text) or self._doc[i-1].get_images(full=True):
                need_img.add(i)

        # ä¸¦è¡Œè™•ç†
        all_results = []
        rotated_pages = []
        result_path = os.path.join(self.output_dir, "result.json")
        with open(result_path, "w", encoding="utf-8") as f:
            json.dump({"results": [], "rotated_pages": []}, f, ensure_ascii=False, indent=2)

        # å•Ÿå‹•ç·šç¨‹æ± 
        with ThreadPoolExecutor(max_workers=4) as exe:
            futures = {
                exe.submit(self.process_page, i, page, need_img, table_pages): i
                for i, page in enumerate(pdf.pages, start=1)
            }
            for fut in as_completed(futures):
                page_results, page_rot = fut.result()
                rotated_pages += page_rot
                all_results += page_results

                # # å¯«å‘é‡åº«
                # for item in page_results:
                #     self.vectorstore.add(
                #         content=item["content"],
                #         page=item["page"],
                #         document_id=self.knowledge_id,
                #         media_type=item["media_type"],
                #         title=self.knowledge_title,
                #         source=item["source"]
                #     )

                # æ›´æ–° result.json
                with open(result_path, "r+", encoding="utf-8") as f:
                    data = json.load(f)
                    data["results"].extend(page_results)
                    data["rotated_pages"] = rotated_pages
                    f.seek(0); f.truncate()
                    json.dump(data, f, ensure_ascii=False, indent=2)

                log(f"âœ… ç¬¬ {futures[fut]} é¡µå¤„ç†å®Œæ¯•ï¼Œå†™å…¥ {len(page_results)} æ¡ï¼›ç´¯è®¡æ—‹è½¬é¡µï¼š{rotated_pages}")

        pdf.close()
        self._doc.close()
        log(f"ğŸ å…¨éƒ¨å®Œæˆï¼Œç”¨æ—¶ {time.time()-t0:.1f}sï¼Œæ€»è®°å½•æ•° {len(all_results)}")
        return all_results, rotated_pages

if __name__ == "__main__":
    processor = PdfProcessor("test.pdf")
    result = processor.optimized_process()


