import io
import json
import os
import re
import time
from concurrent.futures import ProcessPoolExecutor
from datetime import datetime

import fitz  # PyMuPDF
import numpy as np
import ollama
import pdfplumber
import torch
from easyocr import Reader
from PIL import Image, ImageDraw
from transformers import AutoModelForObjectDetection, AutoProcessor


def _render_page(args):
   pdf_path, i, table_pages = args
   doc = fitz.open(pdf_path)
   page = doc.load_page(i - 1)
   dpi = 150 if i in table_pages else 100
   pix = page.get_pixmap(dpi=dpi)
   img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
   doc.close()
   return i, img

def log(msg):
    now = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
    print(f"{now} {msg}")


class PdfProcessor:
    def __init__(
        self,
        pdf_path,
        output_dir="media",
        model_name="gemma3:27b",
        knowledge_id=None,
        vectorstore=None,
        cid_threshold=20
    ):
        self.pdf_path = pdf_path
        self.file_stem = os.path.splitext(os.path.basename(pdf_path))[0]
        self.output_dir = os.path.join(output_dir, "extract_data", self.file_stem)
        self.model_name = model_name
        self.knowledge_id = knowledge_id
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        # EasyOCR
        self.reader = Reader(['ch_tra', 'en'], gpu=torch.cuda.is_available())
        # è¡¨æ ¼åµæ¸¬ model
        self.detector = AutoModelForObjectDetection.from_pretrained("microsoft/table-transformer-detection", revision="no_timm").to(self.device)
        self.processor = AutoProcessor.from_pretrained(
           "microsoft/table-transformer-detection", revision="no_timm")
        self.cid_threshold = cid_threshold
        os.makedirs(self.output_dir, exist_ok=True)
        for sub in ("images", "tables", "ocr_fallback"):
            os.makedirs(os.path.join(self.output_dir, sub), exist_ok=True)

    def should_ocr(self, text: str) -> bool:
        # åŸæœ‰ CID åˆ¤æ–·
        cid_unicode = len(re.findall(r'[\ue000-\uf8ff]', text))
        cid_marker = len(re.findall(r'\(cid:\d+\)', text))
        if cid_unicode + cid_marker >= self.cid_threshold:
            log(f"CID é”æ¨™ ({cid_unicode+cid_marker}) â†’ OCR")
            return True
        return False

    def summarize_image(self, image_paths, prompt):
        if isinstance(image_paths, str):
            image_paths = [image_paths]
        log("[è§£æåœ–ç‰‡æˆ–æ•´é å½±åƒ]")
        system_prompt = (
            "ä½ æ˜¯ä¸€ä½é‡å°åœ–ç‰‡å½±åƒå’Œè¡¨æ ¼å½±åƒé€²è¡Œæå–å…§å®¹çš„åŠ©æ‰‹"
            "è«‹é‚„åŸæ¯å¼µåœ–ç‰‡ä¸­çš„æ–‡å­—æ®µè½ã€è¡¨æ ¼å…§å®¹"
            "å¦‚æœæœ‰æä¾›ocrçš„æ–‡å­—è¾¨è­˜çµæœä¹Ÿå¯ä»¥åƒè€ƒï¼Œæ–‡å­—è¾¨è­˜å¯èƒ½æœ‰éŒ¯èª¤ï¼Œè‹¥å­—è©ä¸åˆé‚è¼¯å¿…é ˆè½‰æ›æˆæ­£å¸¸çš„å­—è©"
            "è‹¥æ˜¯åœ–è¡¨å®Œæ•´å›å‚³æ¯ç­†è³‡æ–™å’Œå…¶è¶¨å‹¢"
            "è‹¥æ˜¯è¡¨æ ¼å…§å®¹ç”¨markdownè¡¨æ ¼æ ¼å¼å›å‚³çµæœ"
        )
        try:
            response = ollama.chat(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt, "images": image_paths}
                ]
            )
            return response['message']['content']
        except Exception as e:
            return f"âŒ åœ–åƒåˆ†æéŒ¯èª¤: {str(e)}"

    def detect_rotation_angle_easyocr(self, ocr_result, min_text_count=5, vertical_angle_range=(75, 105)):
        vertical_texts, short_texts, tall_boxes = 0, 0, 0
        total_texts = len(ocr_result)
        for (box, text, _) in ocr_result:
            x0, y0 = box[0]; x1, y1 = box[1]
            dx, dy = x1 - x0, y1 - y0
            angle = abs(np.arctan2(dy, dx) * 180 / np.pi)
            if vertical_angle_range[0] <= angle <= vertical_angle_range[1]: vertical_texts += 1
            if len(text.strip()) <= 1: short_texts += 1
            w = np.linalg.norm(np.array(box[0]) - np.array(box[1]))
            h = np.linalg.norm(np.array(box[0]) - np.array(box[3]))
            if h > w * 2: tall_boxes += 1
        if total_texts < min_text_count: return 0
        if vertical_texts / total_texts > 0.5 or short_texts / total_texts > 0.4 or tall_boxes / total_texts > 0.4:
            return 90
        return 0
        
    def get_title_from_above(self, img, coords):
        # è¨ˆç®—æ¨™é¡Œç¯„åœ
        x1, y1, x2, y2 = coords
        print(f"è¡¨æ ¼æå–ç¯„åœ:{[x1, y1, x2, y2]}")

        # Xè»¸ç¯„åœï¼šå¾è¡¨æ ¼æœ€å·¦é‚Šåˆ°è¡¨æ ¼å¯¬åº¦çš„ 3/4
        x_range = (x1, x1 + (x2 - x1) * 0.75)
        
        # Yè»¸ç¯„åœï¼šå¾è¡¨æ ¼ä¸Šæ–¹çš„ç©ºé–“çš„ 1/2 é–‹å§‹åˆ°è¡¨æ ¼ä¸Šé‚Šç·£
        y_range = (y1-150, y1+50)

        print(f"æ¨™é¡Œæå–ç¯„åœ:{[x_range[0], y_range[0], x_range[1], y_range[1]]}")
        # åœ¨åŸå§‹åœ–åƒä¸Šç•«å‡ºæ¨™é¡Œç¯„åœ
                
        #draw = ImageDraw.Draw(img)
        #draw.rectangle([x_range[0], y_range[0], x_range[1], y_range[1]], outline="red", width=3)

        # é¡¯ç¤ºåœ–ç‰‡
        #img.show()
        # è£åˆ‡åœ–ç‰‡
        crop = img.crop((x_range[0], y_range[0], x_range[1], y_range[1]))

        # ä½¿ç”¨OCRè®€å–è£åˆ‡å€åŸŸçš„æ–‡å­—
        result = self.reader.readtext(np.array(crop))
        title = "\r\n".join([item[1] for item in result]) if result else "ç„¡æ¨™é¡Œ"
        if len(title)>=25:
            title = "ç„¡æ¨™é¡Œ"
        return title
    
    def calculate_table_area(self,box) -> float:
        x1, y1, x2, y2 = box
        total_table_area = abs((x2 - x1) * (y2 - y1))
        return total_table_area
        
    def extract_table(self,img,i,j,box,table_blocks):
        coords = box.tolist()  # [x1, y1, x2, y2]
        expand_coords = [coords[0]-50,coords[1],coords[2]+50,coords[3]+50]
        cropped = img.crop(expand_coords)
        path = os.path.join(self.output_dir, "tables", f"page{i}_table{j+1}.png")
        cropped.save(path)
        ocr = self.reader.readtext(np.array(cropped))
        merged = "\r\n".join([r[1] for r in ocr])
        box_width = coords[2] - coords[0]
        table_title = self.get_title_from_above(img, coords)
        print(f"æª¢æ¸¬åˆ°çš„æ¨™é¡Œï¼š{table_title}")
        table_blocks.append({
            "page": i,
            "image": path,
            "ocr_text": merged,
            "box_width": box_width,
            "title": table_title
        })
        return table_blocks

    def group_tables_summary(self,table_blocks,table_results):
        # è¡¨æ ¼ç¾¤çµ„é‚è¼¯
        table_blocks.sort(key=lambda x: x["page"])
        grouped, temp = [], [table_blocks[0]] if table_blocks else []

        for i in range(1, len(table_blocks)):
            print("===== groping table =====")
            prev, curr = table_blocks[i-1], table_blocks[i]
            if (
                curr["page"] == prev["page"] + 1
                and abs(curr["box_width"] - prev["box_width"]) / max(prev["box_width"], 1) < 0.05
                and curr["title"] == "ç„¡æ¨™é¡Œ" 
            ):
                temp.append(curr)
            else:
                grouped.append(temp)
                temp = [curr]
        if temp: grouped.append(temp)

        for group_index, group in enumerate(grouped):
            title = [g["title"] for g in group][0] #è·¨é è¡¨æ ¼ä»¥ç¬¬ä¸€å€‹è¡¨æ ¼æ¨™é¡Œ(å› ç‚ºå…¶ä»–çš„æ‡‰è©²éƒ½æ˜¯"ç„¡æ¨™é¡Œ")
            # texts = [g["ocr_text"] for g in group]
            # imgs = [g["image"] for g in group]
            # pages = [g["page"] for g in group]
            for g in group:
                texts = g["ocr_text"]
                imgs = g["image"] 
                pages = g["page"]
                print(f"Title: {title}")
                print(f"OCR: {texts}")
                prompt = (
                    f"ä»¥ä¸‹æ˜¯è¡¨æ ¼æ¨™é¡Œï¼š{title}\r\n(å¦‚æœæ˜¯ç„¡æ¨™é¡Œè«‹ä¾ç…§è¡¨æ ¼å…§å®¹å³å¯)ä»¥ä¸‹æ˜¯ OCR å…§å®¹ï¼š\r\n{chr(10).join(texts)}\r\n"
                    "è«‹æ ¹æ“šOCRçš„å…§å®¹ä»¥åŠæä¾›çš„è¡¨æ ¼åœ–ç‰‡é‚„åŸåœ–ç‰‡ä¸­è¡¨æ ¼çš„æ¶æ§‹å’Œæ¯å€‹å°æ‡‰æ¬„ä½çš„æ–‡å­—å…§å®¹ï¼Œä¸¦ç”¨markdownè¡¨æ ¼æ ¼å¼å›å‚³çµæœ"
                    "è«‹ç›´æ¥æè¿°å…§å®¹ï¼Œä¸éœ€è¦ä»»ä½•é–‹å ´ç™½ã€èªªæ˜æˆ–å¼•å°å¥ã€‚"
                    "åƒ…æä¾›ç´”å…§å®¹ï¼Œä¸è¦åŠ ä¸Š:[å¥½çš„]ã€[ä»¥ä¸‹æ˜¯åˆ†æ]ç­‰å­—å¥"
                    )
                summary = self.summarize_image(imgs, prompt)
                table_results.append({
                    "page": pages,
                    "source": imgs,
                    #"title": title,
                    "content": f"[llm]\r\n{summary}",
                    "media_type":"table"
                })
            log(f"ğŸ“‹ è¡¨æ ¼çµ„ {group_index + 1} LLMå®Œæˆï¼š{summary[:80]}...")
        return table_results

    def extract_texts(self,page,i,page_images,text_results):
        text = page.extract_text() or ""
        if self.should_ocr(text):
            img = page_images[i]
            path = os.path.join(self.output_dir, "ocr_fallback", f"page_{i}.png")
            img.save(path)
            ocr_result = self.reader.readtext(np.array(img))
            ocr_text = "\r\n".join([text for _, text, conf in ocr_result if conf > 0.5]) if ocr_result else ""
            prompt = f"ä»¥ä¸‹åœ–ç‰‡æ˜¯ä¸€é PDFæ–‡ä»¶çš„åŸå§‹å…§å®¹å’Œæ“·å–çš„æ–‡å­—å¦‚ä¸‹:{ocr_text.strip()}ï¼Œè«‹ä»¥åŸå§‹æ–‡å­—å…§å®¹é‡æ§‹é€™æ®µæ–‡å­—æ®µè½ï¼Œé‚„åŸå…¶åŸæ–‡ï¼Œå‹¿åŠ å…¥å¤šé¤˜å¼•è¨€æˆ–è©•è«–"
            summary = self.summarize_image(path, prompt)
            log(f"ç¬¬ {i} é æ–‡å­— OCR+LLM æ‘˜è¦å®Œæˆï¼š[ocr]{ocr_text.strip()}\r\n[llm]{summary}")
            text_results.append({
                "page": i,
                "source": "ocr+llm",
                "content": f"[ocr]{ocr_text.strip()}\r\n[llm]{summary}",
                "media_type":"text"
            })
        else:
            log(f"ç¬¬ {i} é ç´”æ–‡å­—è™•ç†å®Œæˆï¼š{text}...")
            text_results.append({
                "page": i,
                "source": "ori",
                "content": text,
                "media_type":"text"
            })
        return text_results
    
    def extract_imgs(self, doc, i, image_results):
        # è™•ç†åœ–ç‰‡
        fitz_page = doc.load_page(i - 1)
        image_list = fitz_page.get_images(full=True)
        if not image_list:
            return image_results
        print(f"ğŸ“„ ç¬¬ {i} é æ‰¾åˆ° {len(image_list)} å¼µåœ–ç‰‡")

        for img_index, img_info in enumerate(image_list):
            xref = img_info[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]

            # å°‡åœ–ç‰‡è½‰æ›ç‚º PIL åœ–åƒé€²è¡Œ OCR
            img = Image.open(io.BytesIO(image_bytes))
            img_array = np.array(img)
            ocr_result = self.reader.readtext(img_array)
            ocr_text = "\r\n".join([text for _, text, conf in ocr_result if conf > 0.5]) if ocr_result else ""
            print(f"OCR çµæœ: {ocr_result}")

            # å¦‚æœ OCR çµæœé•·åº¦å°æ–¼ 10 å­—ï¼Œå‰‡ä¸Ÿæ£„åœ–ç‰‡ï¼Œè·³éå„²å­˜
            if len(ocr_text) < 10:
                log(f"âš ï¸ ç¬¬ {i} é ç¬¬ {img_index + 1} å¼µåœ–ç‰‡ OCR çµæœå°‘æ–¼ 8 å­—ï¼Œå·²ç•¥é")
                continue  # è·³éé€™å¼µåœ–ç‰‡ï¼Œç›´æ¥è™•ç†ä¸‹ä¸€å¼µ

            # å„²å­˜åœ–ç‰‡
            img_name = f"page_{i}_img_{img_index + 1}.{image_ext}"
            img_path = os.path.join(self.output_dir, "images", img_name)
            with open(img_path, "wb") as f:
                f.write(image_bytes)
            print(f"åœ–ç‰‡ {img_index + 1} å·²å„²å­˜ï¼š{img_path}")

            # å¦‚æœ OCR çµæœé•·åº¦ç¬¦åˆæ¢ä»¶ï¼Œç¹¼çºŒè™•ç†åœ–ç‰‡æ‘˜è¦
            print(f"OCR çµæœ: {ocr_text}")
            prompt = (
                    "è«‹æè¿°é€™å¼µåœ–ç‰‡çš„å…§å®¹ã€‚å¦‚æœæ˜¯æ–‡ç« è«‹é‚„åŸæ–‡ç« çš„æ‰€æœ‰æ–‡å­—å…§å®¹ï¼Œå¦‚æœæ˜¯è¡¨æ ¼è¦ç”¨å’Œåœ–ç‰‡ä¸­åŒæ¨£çš„è¡¨æ ¼æ¶æ§‹å‘ˆç¾æ–‡å­—å…§å®¹ä»¥åŠç›¸å°æ‡‰çš„æ¬„ä½ï¼Œä¸¦ç”¨markdownè¡¨æ ¼æ ¼å¼å›å‚³çµæœ"
                    "è«‹ç›´æ¥æè¿°å…§å®¹ï¼Œä¸éœ€è¦ä»»ä½•é–‹å ´ç™½ã€èªªæ˜æˆ–å¼•å°å¥ã€‚"
                    "åƒ…æä¾›ç´”å…§å®¹ï¼Œä¸è¦åŠ ä¸Š:[å¥½çš„]ã€[ä»¥ä¸‹æ˜¯åˆ†æ]ç­‰å­—å¥"
                    "è‹¥åœ–ç‰‡ç‚ºåœ–è¡¨ï¼Œè«‹æŒ‡å‡º:\r\n"
                    "1.åœ–è¡¨é¡å‹(å¦‚æŠ˜ç·šåœ–ã€é•·æ¢åœ–ç­‰)\r\n"
                    "2.Xè»¸å’ŒYè»¸ä»£è¡¨çš„æ„ç¾©\r\n"
                    "3.æ¯ç­†è³‡æ–™çš„æ•¸å€¼å’Œåç¨±\r\n"
                    "4.è³‡æ–™å‘ˆç¾çš„è¶¨å‹¢ã€æœ€é«˜æˆ–æœ€ä½é»ä»¥åŠå…¶é—œéµè®ŠåŒ–\r\n"
                    "è‹¥åœ–ç‰‡éåœ–è¡¨ï¼Œè«‹æ”¹ç‚ºæè¿°å…¶ä¸»è¦æ§‹æˆèˆ‡é‡è¦è³‡è¨Š"
                        )
            summary = self.summarize_image(img_path, prompt)
            log(f"ğŸ–¼ï¸ ç¬¬ {i} é åœ–ç‰‡LLMè§£æå®Œæˆï¼š[llm]{summary[:80]}...")

            image_results.append({
                "page": i,
                "source": img_path,
                "content": summary,
                "media_type":"image"
            })

        return image_results      

    def save_result(self, result):
        result_path = os.path.join(self.output_dir, "result.json")
        with open(result_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        log(f"âœ… çµæœå·²å„²å­˜è‡³ {result_path}")

    def optimized_process(self):
        start_time = time.time()
        text_results, table_results, image_results = [], [], []
        # å…ˆåˆ¤æ–·å“ªäº›é éœ€è¦æ¸²æŸ“ï¼ˆè¡¨æ ¼ï¼OCRï¼åœ–ç‰‡ï¼‰
        pdf = pdfplumber.open(self.pdf_path)
        doc = fitz.open(self.pdf_path)  # ç”¨æ–¼ extract_imgs ä¸­çš„ load_page
        try:
            table_pages = []
            for i, page in enumerate(pdf.pages, start=1):
                txt = page.extract_text() or ""
                # æ”¹ç‚ºé‡ç”¨å·²é–‹å•Ÿçš„ docï¼Œé¿å…é‡è¤‡é–‹æª”
                has_tables = bool(page.extract_tables())
                has_ocr    = self.should_ocr(txt)
                img_list   = doc.load_page(i-1).get_images(full=True)
                has_images = bool(img_list)
                if has_tables or has_ocr or has_images:
                    table_pages.append(i)
                    
            need_pages = sorted(set(table_pages))
            log(f"ğŸ–¼ï¸ éœ€è¦æ¸²æŸ“é é¢: {need_pages}")

            # â€”â€” 2. ç”¨ ProcessPoolExecutor ä¸¦è¡Œæ¸²æŸ“ â€”â€” 
            page_images = {}
            # ç‚ºäº†è®“ helper æ¥æ”¶åƒæ•¸ï¼Œæˆ‘å€‘æŠŠéœ€è¦çš„è³‡æ–™åŒ…æˆ tuple
            args_list = [(self.pdf_path, i, set(table_pages)) for i in need_pages]
            # max_workers å»ºè­°è¨­æˆ CPU æ ¸å¿ƒæ•¸æˆ–è‡ªè¡Œèª¿æ•´
            with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:
                for i, img in executor.map(_render_page, args_list):
                    page_images[i] = img

                    
            # é¦–å…ˆè™•ç†è¡¨æ ¼é 
            table_blocks = []
            rotated_pages = []
            for i in table_pages:
                log(f"ğŸ“„ æª¢æŸ¥ç¬¬ {i} é è¡¨æ ¼ä½ç½®...")
                img = page_images[i]
                page = pdf.pages[i - 1]
                #å…ˆåˆ¤æ–·æ˜¯å¦éœ€è¦è½‰å‘
                ocr_result = self.reader.readtext(np.array(img))
                angle = self.detect_rotation_angle_easyocr(ocr_result)
                if angle == 90:
                    img = img.rotate(-90, expand=True)
                    page_images[i] = img
                    ocr_result = self.reader.readtext(np.array(img))
                    rotated_pages.append(i)
                #å…ˆæª¢æ¸¬è¡¨æ ¼åº§æ¨™
                inputs = self.processor(images=img, return_tensors="pt").to(self.device)
                with torch.no_grad():
                    outputs = self.detector(**inputs)
                target_sizes = torch.tensor([img.size[::-1]]).to(self.device)
                results = self.processor.post_process_object_detection(outputs, threshold=0.3, target_sizes=target_sizes)[0]
        
                #é é¢é•·å¯¬
                # ç²å–é é¢é‚Šç•Œè³‡è¨Š
                #page_rect = page.rects[0]
                page_width, page_height = img.size # è¨ˆç®—é é¢å¯¬åº¦ã€é«˜åº¦ ï¼ƒpage.widthå’Œheightä¸ä¸€å®šç­‰æ–¼åœ–ç‰‡çš„åƒç´ å°ºå¯¸
                page_area = page_width * page_height
                total_table_area = 0
                for j, box in enumerate(results["boxes"]):
                    # è¨ˆç®—è¡¨æ ¼ä½”é é¢é¢ç©çš„æ¯”ä¾‹
                    total_table_area += self.calculate_table_area(box)
                    table_blocks = self.extract_table(img,i,j,box,table_blocks)
                table_area_ratio = total_table_area / page_area if page_area > 0 else 0.0
                log(f"ç¬¬ {i} é  è¡¨æ ¼ä½”é é¢é¢ç©æ¯”ä¾‹ç‚ºï¼š{table_area_ratio:.2f}")
                # å¦‚æœè¡¨æ ¼ä½”æ¯”å°æ–¼15%ï¼Œé€²è¡Œæ–‡å­—å’Œåœ–ç‰‡æå–
                if table_area_ratio < 0.45:
                    log(f"è¡¨æ ¼ä½”æ¯”å°æ–¼45%ï¼Œé–‹å§‹é€²è¡Œæ–‡å­—å’Œåœ–ç‰‡æå–...")
                    text_results = self.extract_texts(page, i, page_images, text_results)
                    image_results = self.extract_imgs(doc, i, image_results)
            
            table_results = self.group_tables_summary(table_blocks,table_results)

            # è¡¨æ ¼è™•ç†å®Œæˆå¾Œï¼Œå†è™•ç†æ²’æœ‰è¡¨æ ¼çš„é é¢
            for i, page in enumerate(pdf.pages, start=1):
                if i in table_pages:
                    continue  # è·³éè¡¨æ ¼é 
                text_results = self.extract_texts(page,i,page_images,text_results)
                # è™•ç†åœ–ç‰‡
                image_results = self.extract_imgs(doc,i,image_results)

            result = text_results + table_results + image_results
            self.save_result(result)
        finally:
            pdf.close()
            doc.close()

        end_time = time.time()
        log(f"âœ… PDF å…¨éƒ¨è™•ç†å®Œæˆï¼Œç”¨æ™‚ {end_time - start_time:.2f} ç§’")

        return result, rotated_pages


if __name__ == "__main__":
    processor = PdfProcessor("test.pdf")
    result = processor.optimized_process()
