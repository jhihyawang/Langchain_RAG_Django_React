    def __init__(self, pdf_path, vectorstore="chroma_user_db", output_dir="media", model_name="gemma3:27b", knowledge_id=None, knowledge_title="æœªçŸ¥æ–‡ä»¶",cid_threshold=20):
        self.pdf_path = pdf_path
        self.file_stem = os.path.splitext(os.path.basename(pdf_path))[0]
        self.output_dir = os.path.join(output_dir,"extract_data",self.file_stem)
        self.model_name = model_name
        self.knowledge_id = knowledge_id
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        # ğŸ”½ è®“ OCR reader ç”¨ GPU
        self.reader = Reader(['ch_tra', 'en'], gpu=(self.device=="cuda"))
        # ğŸ”½ Detector, Model ä¹Ÿéƒ½æ”¾ä¸Š GPU
        self.detector = AutoModelForObjectDetection.from_pretrained("microsoft/table-transformer-detection", revision="no_timm").to(self.device)
        self.processor = AutoProcessor.from_pretrained("microsoft/table-transformer-detection", revision="no_timm")
        self.proc = AutoImageProcessor.from_pretrained("microsoft/table-transformer-structure-recognition-v1.1-all")
        self.proc.size['shortest_edge'] = 800
        self.model = TableTransformerForObjectDetection.from_pretrained("microsoft/table-transformer-structure-recognition-v1.1-all").to(self.device)
        self.cid_threshold = cid_threshold
        self.dpi = 300
        self.vectorstore = VectorStoreHandler(db_path=vectorstore)
        self.knowledge_title = knowledge_title
     
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, "images"), exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, "tables"), exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, "ocr_fallback"), exist_ok=True)


    def extract_tables(self, img, page_num, tbl_idx, box, media_type):
        try:
            # ...ï¼ˆå‰é¢ç¨‹å¼åŒåŸæœ¬ï¼‰
            inputs = self.proc(images=tbl_crop, return_tensors="pt")
            # ğŸ”½ ä¿è­‰ inputs tensor éƒ½åœ¨ self.device
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            with torch.no_grad():
                out = self.model(**inputs)
            tgt_sz  = torch.tensor([tbl_crop.size[::-1]]).to(self.device)
            results = self.proc.post_process_object_detection(out, threshold=0.5, target_sizes=tgt_sz)[0]


                if angle == 90:
                    img = img.rotate(-90, expand=True)
                    rotated_pages.append(i)
                    log(f"ç¬¬ {i} é¡µæ—‹è½‰ 90 åº¦")

                # ğŸ”½ ä½¿ç”¨ GPU
                inputs = self.processor(images=img, return_tensors="pt")
                inputs = {k: v.to(self.device) for k, v in inputs.items()}
                with torch.no_grad():
                    outputs = self.detector(**inputs)
                target_sizes = torch.tensor([img.size[::-1]]).to(self.device)
                det = self.processor.post_process_object_detection(
                    outputs, threshold=0.5, target_sizes=target_sizes
                )[0]

                # ...ï¼ˆç•¥ï¼šå…¶é¤˜éƒ¨åˆ†åŒç†ï¼Œå¦‚ä¸‹ï¼‰
                masked_img = self.mask_table_regions(img, det["boxes"])
                inputs2 = self.proc(images=masked_img, return_tensors="pt")
                inputs2 = {k: v.to(self.device) for k, v in inputs2.items()}
                with torch.no_grad():
                    out2 = self.model(**inputs2)
                tgt2 = torch.tensor([masked_img.size[::-1]]).to(self.device)
                sec = self.proc.post_process_object_detection(
                    out2, threshold=0.5, target_sizes=tgt2
                )[0]
                # ...ï¼ˆç•¥ï¼‰
